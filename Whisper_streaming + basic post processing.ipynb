{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKyov1/JJo5T/KS981dpj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acrching/WhisperX/blob/main/Whisper_streaming%20%2B%20basic%20post%20processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install streamlink\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "JKfuTLUBsiyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMtwX-kLsCXY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import queue\n",
        "import threading\n",
        "import ffmpeg\n",
        "import streamlink\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "AUDIO_BUFFER_SIZE = 30  # Buffer size in seconds\n",
        "\n",
        "class WhisperOnline:\n",
        "    def __init__(self, model_size, hls_url):\n",
        "        self.audio_buffer = queue.Queue(maxsize=AUDIO_BUFFER_SIZE * 16000)\n",
        "        self.model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "        self.hls_url = hls_url\n",
        "        self.context_words = []\n",
        "\n",
        "    def download_audio(self):\n",
        "        streams = streamlink.streams(self.hls_url)\n",
        "        stream_url = streams['best'].url\n",
        "\n",
        "        process = (\n",
        "            ffmpeg\n",
        "            .input(stream_url)\n",
        "            .output('pipe:', format='wav', acodec='pcm_s16le', ac=1, ar='16k')\n",
        "            .run_async(pipe_stdout=True, pipe_stderr=True)\n",
        "        )\n",
        "        while True:\n",
        "            in_bytes = process.stdout.read(1024)\n",
        "            if not in_bytes:\n",
        "                break\n",
        "            self.audio_buffer.put(np.frombuffer(in_bytes, np.int16).astype(np.float32) / 32768.0)\n",
        "\n",
        "    def transcribe_audio(self):\n",
        "        while True:\n",
        "            if not self.audio_buffer.empty():\n",
        "                audio_chunk = []\n",
        "                for _ in range(16000 * 10):\n",
        "                    if not self.audio_buffer.empty():\n",
        "                        audio_chunk.append(self.audio_buffer.get())\n",
        "                    else:\n",
        "                        break\n",
        "                if len(audio_chunk) == 0:\n",
        "                    break\n",
        "                audio_chunk = np.concatenate(audio_chunk)\n",
        "\n",
        "                # Transcribe with context\n",
        "                context = ' '.join(self.context_words) if self.context_words else None\n",
        "                segments, _ = self.model.transcribe(audio_chunk, initial_prompt=context, beam_size=5)\n",
        "\n",
        "                new_transcription = []\n",
        "                for segment in segments:\n",
        "                    new_transcription.append(segment.text)\n",
        "                    self.context_words.extend(segment.text.split())\n",
        "\n",
        "                # Keep only the last 200 words in context\n",
        "                if len(self.context_words) > 200:\n",
        "                    self.context_words = self.context_words[-200:]\n",
        "\n",
        "                # Print the new transcription segment\n",
        "                new_text = ' '.join(new_transcription)\n",
        "                print(self.post_process_transcription(new_text))\n",
        "\n",
        "    def post_process_transcription(self, text):\n",
        "        # Basic post-processing to correct common errors\n",
        "        text = text.replace(' ,', ',').replace(' .', '.').replace(' ?', '?').replace(' !', '!')\n",
        "        text = text.replace('  ', ' ')\n",
        "        return text\n",
        "\n",
        "    def run(self):\n",
        "        download_thread = threading.Thread(target=self.download_audio)\n",
        "        transcribe_thread = threading.Thread(target=self.transcribe_audio)\n",
        "\n",
        "        download_thread.start()\n",
        "        transcribe_thread.start()\n",
        "\n",
        "        download_thread.join()\n",
        "        transcribe_thread.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_size = 'large-v2'  # Model size for faster-whisper\n",
        "    hls_url = 'YOUR_HLS_STREAM_URL'  # Replace with your HLS stream URL\n",
        "\n",
        "    whisper_online = WhisperOnline(model_size, hls_url)\n",
        "    whisper_online.run()"
      ]
    }
  ]
}
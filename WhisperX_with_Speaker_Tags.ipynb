{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKbF/4eHjzmanydZeK3xxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acrching/WhisperX/blob/main/WhisperX_with_Speaker_Tags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the webcast link does not end in mp3 or mp4, download here using yt-dlp, else skip."
      ],
      "metadata": {
        "id": "PPGNZzAmquIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNVivZKzqnqw"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp\n",
        "!yt-dlp #insert command from The Stream Detector here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install WhisperX"
      ],
      "metadata": {
        "id": "sKspHf3Cr0uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/m-bain/whisperx.git\n",
        "import whisperx\n",
        "import gc"
      ],
      "metadata": {
        "id": "Kez67EfGr-5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to transcribe!"
      ],
      "metadata": {
        "id": "0ahcByLQs_qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "audio_file = \"audio name here.mp3\" # you can directly paste the URL if mp3 or mp4\n",
        "batch_size = 32 # reduce if low on GPU mem\n",
        "compute_type = \"float16\"\n",
        "\n",
        "# 1. Transcribe with WhisperX\n",
        "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "result = model.transcribe(audio, language='en')\n",
        "\n",
        "# Extract and save the transcript without timestamps and speaker tags\n",
        "transcript_text = \" \".join([segment['text'] for segment in result['segments']])\n",
        "\n",
        "with open(\"output.txt\", \"w\") as f: # you can change the text file name\n",
        "    f.write(transcript_text)\n",
        "\n",
        "print(\"Transcript saved\")\n",
        "\n",
        "print(result[\"segments\"]) # before alignment\n",
        "\n",
        "# 2. Align whisper output\n",
        "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
        "\n",
        "print(result[\"segments\"]) # after alignment"
      ],
      "metadata": {
        "id": "zKY-uaZ2sUps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add speaker tags!"
      ],
      "metadata": {
        "id": "_NkTW-Qnt5zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Assign speaker labels\n",
        "diarize_model = whisperx.DiarizationPipeline(use_auth_token='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', device=device)\n",
        "\n",
        "# add min/max number of speakers if known\n",
        "diarize_segments = diarize_model(audio)\n",
        "# diarize_model(audio, min_speakers=min_speakers, max_speakers=max_speakers)\n",
        "\n",
        "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
        "\n",
        "current_speaker = None\n",
        "current_text = \"\"\n",
        "output_text = \"\"\n",
        "\n",
        "for segment in result[\"segments\"]:\n",
        "    if segment[\"speaker\"] != current_speaker:\n",
        "        if current_speaker:\n",
        "            output_text += f\"Speaker {current_speaker}^ {current_text.strip()}\\n\\n\"\n",
        "        current_speaker = segment[\"speaker\"]\n",
        "        current_text = \"\"\n",
        "    current_text += segment[\"text\"] + \" \"\n",
        "\n",
        "# Add the last speaker's text\n",
        "if current_speaker:\n",
        "    output_text += f\"Speaker {current_speaker}^ {current_text.strip()}\\n\"\n",
        "\n",
        "# Save to a text file, specifying UTF-8 encoding to handle Unicode characters\n",
        "output_file = \"output with speakers.txt\" # you can change the text file name\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f: # Specify UTF-8 encoding\n",
        "    f.write(output_text)\n",
        "\n",
        "print(diarize_segments)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "moal1A26t81A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}